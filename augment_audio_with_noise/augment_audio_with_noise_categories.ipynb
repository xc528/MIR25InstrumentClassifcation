{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Audio Augmentation with Noise Categories\n",
        "\n",
        "This notebook augments 1000 original audio files by mixing them with noise from 10 categories, generating **10,000 augmented audio files** (1000 √ó 10 categories).\n",
        "\n",
        "## Overview\n",
        "\n",
        "- **Input**: 1000 original audio files from `audio_1000_balanced/`\n",
        "- **Noise Source**: Noise files from `noises/` directory with 10 categories (ambience, applause, bird, crowd, fan, microphone, rain, street, talking, white_noise)\n",
        "- **Output**: 10,000 augmented audio files in `augmented_audio/` + CSV metadata file\n",
        "- **Features**:\n",
        "  - Random noise selection from each category\n",
        "  - Random amplitude gain (0.6-1.4)\n",
        "  - Random pitch shift (-2 to +2 semitones)\n",
        "  - Random SNR mixing (8-20 dB)\n",
        "  - Resume capability (skips existing files)\n",
        "  - Incremental CSV saving every 1000 files\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Imports and Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import csv\n",
        "import random\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "\n",
        "import torch\n",
        "import torchaudio\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "print(\"‚úì Imports successful\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"TorchAudio version: {torchaudio.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configuration\n",
        "\n",
        "Set up all parameters and paths for the augmentation process.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Audio processing parameters\n",
        "SAMPLE_RATE = 44100\n",
        "NOISE_AMPLITUDE_MIN = 0.6\n",
        "NOISE_AMPLITUDE_MAX = 1.4\n",
        "PITCH_SHIFT_MIN = -2  # semitones\n",
        "PITCH_SHIFT_MAX = 2   # semitones\n",
        "SNR_MIN = 8   # dB\n",
        "SNR_MAX = 20  # dB\n",
        "\n",
        "# Directory paths\n",
        "AUDIO_DIR = Path(\"audio_1000_balanced\")\n",
        "NOISES_DIR = Path(\"noises\")\n",
        "OUTPUT_AUDIO_DIR = Path(\"augmented_audio\")\n",
        "CSV_INPUT = \"audio_labels_1000_balanced.csv\"\n",
        "CSV_OUTPUT = \"augmented_audio_noise_10000.csv\"\n",
        "\n",
        "# Noise categories (auto-detected from folder names)\n",
        "NOISE_CATEGORIES = [\n",
        "    \"ambience\", \"applause\", \"bird\", \"crowd\", \"fan\",\n",
        "    \"microphone\", \"rain\", \"street\", \"talking\", \"white_noise\"\n",
        "]\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "RANDOM_SEED = 42\n",
        "random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)\n",
        "\n",
        "print(\"‚úì Configuration loaded\")\n",
        "print(f\"Sample rate: {SAMPLE_RATE} Hz\")\n",
        "print(f\"Noise categories: {len(NOISE_CATEGORIES)}\")\n",
        "print(f\"Random seed: {RANDOM_SEED}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Helper Functions\n",
        "\n",
        "### 3.1 File Finding and Loading\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def find_audio_file(uuid4: str, audio_dir: Path) -> Optional[Path]:\n",
        "    \"\"\"\n",
        "    Find audio file by UUID4.\n",
        "    \n",
        "    Args:\n",
        "        uuid4: UUID4 string from CSV\n",
        "        audio_dir: Directory containing audio files\n",
        "        \n",
        "    Returns:\n",
        "        Path to audio file or None if not found\n",
        "    \"\"\"\n",
        "    pattern = f\"*{uuid4}*.wav\"\n",
        "    matches = [f for f in audio_dir.glob(pattern) if not f.name.startswith(\"._\")]\n",
        "    if matches:\n",
        "        return matches[0]\n",
        "    return None\n",
        "\n",
        "\n",
        "def load_audio(file_path: Path, target_sr: int = SAMPLE_RATE) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Load audio file, convert to mono, and resample to target sample rate.\n",
        "    \n",
        "    Args:\n",
        "        file_path: Path to audio file\n",
        "        target_sr: Target sample rate\n",
        "        \n",
        "    Returns:\n",
        "        Audio tensor of shape (1, samples) - mono channel\n",
        "    \"\"\"\n",
        "    with torch.no_grad():\n",
        "        waveform, sr = torchaudio.load(str(file_path))\n",
        "        \n",
        "        # Convert to mono if stereo\n",
        "        if waveform.shape[0] > 1:\n",
        "            waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
        "        \n",
        "        # Resample if needed\n",
        "        if sr != target_sr:\n",
        "            resampler = torchaudio.transforms.Resample(sr, target_sr)\n",
        "            waveform = resampler(waveform)\n",
        "        \n",
        "        # Ensure no gradients\n",
        "        waveform = waveform.detach()\n",
        "    \n",
        "    return waveform\n",
        "\n",
        "print(\"‚úì File finding and loading functions defined\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 Audio Transformations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def apply_pitch_shift(waveform: torch.Tensor, n_steps: float, sample_rate: int = SAMPLE_RATE) -> torch.Tensor:\n",
        "    \"\"\"Apply pitch shift to audio waveform.\"\"\"\n",
        "    if n_steps == 0:\n",
        "        return waveform\n",
        "    \n",
        "    pitch_shift = torchaudio.transforms.PitchShift(\n",
        "        sample_rate=sample_rate,\n",
        "        n_steps=n_steps\n",
        "    )\n",
        "    shifted = pitch_shift(waveform)\n",
        "    return shifted.detach()\n",
        "\n",
        "\n",
        "def apply_amplitude_gain(waveform: torch.Tensor, gain: float) -> torch.Tensor:\n",
        "    \"\"\"Apply amplitude gain to audio waveform.\"\"\"\n",
        "    return waveform * gain\n",
        "\n",
        "\n",
        "def match_length(noise: torch.Tensor, target_length: int) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Match noise length to target length by looping or trimming.\n",
        "    \n",
        "    - If noise is shorter: loop (tile) it\n",
        "    - If noise is longer: trim it\n",
        "    \"\"\"\n",
        "    noise_length = noise.shape[1]\n",
        "    \n",
        "    if noise_length < target_length:\n",
        "        # Loop the noise\n",
        "        num_repeats = (target_length // noise_length) + 1\n",
        "        noise = noise.repeat(1, num_repeats)\n",
        "        noise = noise[:, :target_length]\n",
        "    elif noise_length > target_length:\n",
        "        # Trim the noise\n",
        "        noise = noise[:, :target_length]\n",
        "    \n",
        "    return noise\n",
        "\n",
        "print(\"‚úì Audio transformation functions defined\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3 SNR Mixing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def mix_with_snr(clean: torch.Tensor, noise: torch.Tensor, snr_db: float) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Mix clean audio with noise at specified SNR (Signal-to-Noise Ratio).\n",
        "    \n",
        "    Formula: SNR = 20 * log10(clean_rms / noise_scaled_rms)\n",
        "    This ensures the clean audio dominates while adding realistic noise.\n",
        "    \"\"\"\n",
        "    # Ensure inputs don't require grad\n",
        "    clean = clean.detach() if clean.requires_grad else clean\n",
        "    noise = noise.detach() if noise.requires_grad else noise\n",
        "    \n",
        "    # Calculate RMS (Root Mean Square)\n",
        "    clean_rms = torch.sqrt(torch.mean(clean ** 2))\n",
        "    noise_rms = torch.sqrt(torch.mean(noise ** 2))\n",
        "    \n",
        "    # Avoid division by zero\n",
        "    if noise_rms == 0:\n",
        "        return clean\n",
        "    \n",
        "    # Calculate scaling factor for noise\n",
        "    # noise_scaled_rms = clean_rms / 10^(SNR/20)\n",
        "    target_noise_rms = clean_rms / (10 ** (snr_db / 20.0))\n",
        "    noise_scale = target_noise_rms / noise_rms\n",
        "    \n",
        "    # Scale noise\n",
        "    noise_scaled = noise * noise_scale\n",
        "    \n",
        "    # Mix\n",
        "    mixed = clean + noise_scaled\n",
        "    \n",
        "    # Normalize if clipping occurs\n",
        "    max_val = torch.max(torch.abs(mixed))\n",
        "    if max_val > 1.0:\n",
        "        mixed = mixed / max_val\n",
        "    \n",
        "    # Ensure output doesn't require grad\n",
        "    return mixed.detach()\n",
        "\n",
        "print(\"‚úì SNR mixing function defined\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.4 Noise File Loading\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_noise_files(noises_dir: Path) -> Dict[str, List[Path]]:\n",
        "    \"\"\"\n",
        "    Load all noise files from each category folder.\n",
        "    \n",
        "    Returns:\n",
        "        Dictionary mapping category names to lists of noise file paths\n",
        "    \"\"\"\n",
        "    noise_files = {}\n",
        "    \n",
        "    for category in NOISE_CATEGORIES:\n",
        "        category_dir = noises_dir / category\n",
        "        if not category_dir.exists():\n",
        "            print(f\"Warning: Category folder '{category}' not found, skipping.\")\n",
        "            continue\n",
        "        \n",
        "        # Find all audio files in the category folder (supports .mp3 and .wav)\n",
        "        files = sorted(list(category_dir.glob(\"*.mp3\")) + list(category_dir.glob(\"*.wav\")))\n",
        "        if len(files) == 0:\n",
        "            print(f\"Warning: No audio files found in '{category}', skipping.\")\n",
        "            continue\n",
        "        \n",
        "        noise_files[category] = files\n",
        "        print(f\"Loaded {len(files)} noise files from '{category}'\")\n",
        "    \n",
        "    return noise_files\n",
        "\n",
        "print(\"‚úì Noise file loading function defined\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.5 Main Augmentation Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def augment_audio(\n",
        "    clean_audio: torch.Tensor,\n",
        "    noise_file: Path,\n",
        "    snr_db: float,\n",
        "    amplitude_gain: float,\n",
        "    pitch_shift: float\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Augment clean audio with noise, applying transformations.\n",
        "    \n",
        "    Process:\n",
        "    1. Load noise file\n",
        "    2. Apply amplitude gain\n",
        "    3. Apply pitch shift\n",
        "    4. Match length to clean audio\n",
        "    5. Mix with SNR normalization\n",
        "    \"\"\"\n",
        "    # Ensure clean audio doesn't require grad\n",
        "    clean_audio = clean_audio.detach() if clean_audio.requires_grad else clean_audio\n",
        "    \n",
        "    # Load noise\n",
        "    noise = load_audio(noise_file)\n",
        "    \n",
        "    # Apply transformations to noise\n",
        "    noise = apply_amplitude_gain(noise, amplitude_gain)\n",
        "    noise = apply_pitch_shift(noise, pitch_shift)\n",
        "    \n",
        "    # Match length\n",
        "    target_length = clean_audio.shape[1]\n",
        "    noise = match_length(noise, target_length)\n",
        "    \n",
        "    # Mix with SNR\n",
        "    augmented = mix_with_snr(clean_audio, noise, snr_db)\n",
        "    \n",
        "    # Ensure final output doesn't require grad\n",
        "    return augmented.detach()\n",
        "\n",
        "print(\"‚úì Main augmentation function defined\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Initialization and Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Create output directory\n",
        "OUTPUT_AUDIO_DIR.mkdir(exist_ok=True)\n",
        "print(f\"Output directory: {OUTPUT_AUDIO_DIR}\")\n",
        "\n",
        "# Load noise files\n",
        "print(\"\\nLoading noise files...\")\n",
        "noise_files = load_noise_files(NOISES_DIR)\n",
        "\n",
        "if len(noise_files) == 0:\n",
        "    raise ValueError(\"Error: No noise files found!\")\n",
        "\n",
        "print(f\"\\n‚úì Found {len(noise_files)} noise categories\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Load Original Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load original CSV\n",
        "print(f\"Loading CSV: {CSV_INPUT}\")\n",
        "original_rows = []\n",
        "with open(CSV_INPUT, 'r') as f:\n",
        "    reader = csv.DictReader(f)\n",
        "    for row in reader:\n",
        "        original_rows.append(row)\n",
        "\n",
        "print(f\"‚úì Loaded {len(original_rows)} original audio files\")\n",
        "print(f\"CSV columns: {list(original_rows[0].keys())}\")\n",
        "\n",
        "# Prepare output CSV structure\n",
        "fieldnames = list(original_rows[0].keys()) + ['noise_category']\n",
        "print(f\"Output CSV will have columns: {fieldnames}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Resume Capability Setup\n",
        "\n",
        "Check for existing files and CSV entries to enable resume functionality.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load existing CSV if it exists to resume\n",
        "existing_entries = {}\n",
        "if Path(CSV_OUTPUT).exists():\n",
        "    print(f\"Found existing CSV: {CSV_OUTPUT}\")\n",
        "    with open(CSV_OUTPUT, 'r') as f:\n",
        "        reader = csv.DictReader(f)\n",
        "        for row in reader:\n",
        "            # Create a key from original metadata + noise category\n",
        "            key = (row['uuid4'], row['noise_category'])\n",
        "            existing_entries[key] = row\n",
        "    print(f\"‚úì Loaded {len(existing_entries)} existing entries from CSV\")\n",
        "else:\n",
        "    print(f\"No existing CSV found. Starting fresh.\")\n",
        "\n",
        "# Track which files already exist\n",
        "existing_files = set()\n",
        "if OUTPUT_AUDIO_DIR.exists():\n",
        "    for f in OUTPUT_AUDIO_DIR.glob(\"*.wav\"):\n",
        "        existing_files.add(f.name)\n",
        "    print(f\"‚úì Found {len(existing_files)} existing augmented files in {OUTPUT_AUDIO_DIR}\")\n",
        "else:\n",
        "    print(f\"Output directory is empty. Starting fresh.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Main Augmentation Loop\n",
        "\n",
        "This cell processes all original audio files and generates augmented versions with each noise category.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize tracking variables\n",
        "output_rows = []\n",
        "failed_files = []\n",
        "files_processed = 0\n",
        "augmented_files_count = 0\n",
        "csv_save_interval = 1000  # Save CSV every 1000 augmented files\n",
        "\n",
        "print(\"Starting augmentation...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Process each original audio file\n",
        "for original_row in tqdm(original_rows, desc=\"Processing audio files\"):\n",
        "    uuid4 = original_row['uuid4']\n",
        "    \n",
        "    # Find audio file\n",
        "    audio_file = find_audio_file(uuid4, AUDIO_DIR)\n",
        "    if audio_file is None:\n",
        "        print(f\"\\nWarning: Audio file not found for UUID {uuid4}, skipping.\")\n",
        "        failed_files.append(uuid4)\n",
        "        continue\n",
        "    \n",
        "    # Load clean audio\n",
        "    try:\n",
        "        clean_audio = load_audio(audio_file)\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError loading audio file {audio_file}: {e}\")\n",
        "        failed_files.append(uuid4)\n",
        "        continue\n",
        "    \n",
        "    # Get original filename without extension for output naming\n",
        "    original_filename = audio_file.stem\n",
        "    \n",
        "    # Augment with each noise category\n",
        "    for category in NOISE_CATEGORIES:\n",
        "        if category not in noise_files:\n",
        "            continue\n",
        "        \n",
        "        # Check if this file already exists\n",
        "        output_filename = f\"{original_filename}_{category}.wav\"\n",
        "        output_path = OUTPUT_AUDIO_DIR / output_filename\n",
        "        entry_key = (uuid4, category)\n",
        "        \n",
        "        # Skip if file exists and entry is in CSV\n",
        "        if output_filename in existing_files and entry_key in existing_entries:\n",
        "            # Add existing entry to output_rows to maintain complete CSV\n",
        "            output_rows.append(existing_entries[entry_key])\n",
        "            augmented_files_count += 1  # Count skipped files too\n",
        "            continue\n",
        "        \n",
        "        # Randomly select one noise file from this category\n",
        "        noise_file = random.choice(noise_files[category])\n",
        "        \n",
        "        # Generate random parameters\n",
        "        amplitude_gain = random.uniform(NOISE_AMPLITUDE_MIN, NOISE_AMPLITUDE_MAX)\n",
        "        pitch_shift = random.uniform(PITCH_SHIFT_MIN, PITCH_SHIFT_MAX)\n",
        "        snr_db = random.uniform(SNR_MIN, SNR_MAX)\n",
        "        \n",
        "        # Augment audio\n",
        "        try:\n",
        "            augmented_audio = augment_audio(\n",
        "                clean_audio,\n",
        "                noise_file,\n",
        "                snr_db,\n",
        "                amplitude_gain,\n",
        "                pitch_shift\n",
        "            )\n",
        "            \n",
        "            # Ensure tensor doesn't require grad for saving\n",
        "            with torch.no_grad():\n",
        "                augmented_audio = augmented_audio.detach().clone()\n",
        "            \n",
        "            # Save augmented audio\n",
        "            torchaudio.save(\n",
        "                str(output_path),\n",
        "                augmented_audio,\n",
        "                SAMPLE_RATE\n",
        "            )\n",
        "            \n",
        "            # Add row to output CSV\n",
        "            new_row = original_row.copy()\n",
        "            new_row['noise_category'] = category\n",
        "            output_rows.append(new_row)\n",
        "            \n",
        "            # Update existing files set\n",
        "            existing_files.add(output_filename)\n",
        "            augmented_files_count += 1\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"\\nError augmenting {audio_file} with {category}: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            continue\n",
        "    \n",
        "    files_processed += 1\n",
        "    \n",
        "    # Save CSV incrementally every 1000 augmented files\n",
        "    if augmented_files_count > 0 and augmented_files_count % csv_save_interval == 0:\n",
        "        print(f\"\\nüíæ Saving incremental CSV ({augmented_files_count} augmented files, {files_processed} original files processed)...\")\n",
        "        # Merge existing + new entries for incremental save\n",
        "        incremental_rows = []\n",
        "        processed_keys_incremental = set()\n",
        "        \n",
        "        # Add all processed entries so far\n",
        "        for row in output_rows:\n",
        "            key = (row['uuid4'], row['noise_category'])\n",
        "            processed_keys_incremental.add(key)\n",
        "            incremental_rows.append(row)\n",
        "        \n",
        "        # Add existing entries that haven't been reprocessed\n",
        "        for key, row in existing_entries.items():\n",
        "            if key not in processed_keys_incremental:\n",
        "                incremental_rows.append(row)\n",
        "        \n",
        "        # Sort for consistency\n",
        "        incremental_rows.sort(key=lambda x: (x['uuid4'], x['noise_category']))\n",
        "        \n",
        "        with open(CSV_OUTPUT, 'w', newline='') as f:\n",
        "            writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
        "            writer.writeheader()\n",
        "            writer.writerows(incremental_rows)\n",
        "        print(f\"‚úì Saved {len(incremental_rows)} entries to {CSV_OUTPUT}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úì Augmentation loop completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Final CSV Generation\n",
        "\n",
        "Merge all entries (existing + newly processed) into the final CSV file.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write final output CSV (merge existing + new entries)\n",
        "print(f\"Writing final output CSV: {CSV_OUTPUT}\")\n",
        "\n",
        "# Merge existing entries that weren't reprocessed\n",
        "all_rows = []\n",
        "processed_keys = set()\n",
        "\n",
        "# Add all processed entries\n",
        "for row in output_rows:\n",
        "    key = (row['uuid4'], row['noise_category'])\n",
        "    processed_keys.add(key)\n",
        "    all_rows.append(row)\n",
        "\n",
        "# Add existing entries that weren't reprocessed\n",
        "for key, row in existing_entries.items():\n",
        "    if key not in processed_keys:\n",
        "        all_rows.append(row)\n",
        "\n",
        "# Sort by uuid4 and noise_category for consistency\n",
        "all_rows.sort(key=lambda x: (x['uuid4'], x['noise_category']))\n",
        "\n",
        "# Write final CSV\n",
        "with open(CSV_OUTPUT, 'w', newline='') as f:\n",
        "    writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
        "    writer.writeheader()\n",
        "    writer.writerows(all_rows)\n",
        "\n",
        "print(f\"‚úì Final CSV contains {len(all_rows)} entries (expected: {len(original_rows) * len(NOISE_CATEGORIES)})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Summary and Results\n",
        "\n",
        "Display final statistics and summary of the augmentation process.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate statistics\n",
        "new_files_generated = len([r for r in output_rows if (r['uuid4'], r['noise_category']) not in existing_entries])\n",
        "\n",
        "# Print summary\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"AUGMENTATION SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Number of noise categories found: {len(noise_files)}\")\n",
        "print(f\"Number of original audio files processed: {files_processed}\")\n",
        "print(f\"Number of new augmented files generated in this run: {new_files_generated}\")\n",
        "print(f\"Total augmented files (existing + new): {len(all_rows)}\")\n",
        "print(f\"Expected total augmented files: {len(original_rows) * len(NOISE_CATEGORIES)}\")\n",
        "\n",
        "if failed_files:\n",
        "    print(f\"\\n‚ö†Ô∏è  Warning: {len(failed_files)} files failed to process\")\n",
        "    if len(failed_files) <= 10:\n",
        "        print(f\"Failed UUIDs: {failed_files}\")\n",
        "    else:\n",
        "        print(f\"First 10 failed UUIDs: {failed_files[:10]}\")\n",
        "\n",
        "print(f\"\\nüìÅ Output audio directory: {OUTPUT_AUDIO_DIR}\")\n",
        "print(f\"üìÑ Output CSV: {CSV_OUTPUT}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Verify file counts\n",
        "actual_files = len(list(OUTPUT_AUDIO_DIR.glob(\"*.wav\")))\n",
        "print(f\"\\nüìä Verification:\")\n",
        "print(f\"  - Files in directory: {actual_files}\")\n",
        "print(f\"  - Entries in CSV: {len(all_rows)}\")\n",
        "if actual_files == len(all_rows):\n",
        "    print(\"  ‚úì File count matches CSV entries!\")\n",
        "else:\n",
        "    print(f\"  ‚ö†Ô∏è  Mismatch: {abs(actual_files - len(all_rows))} difference\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
